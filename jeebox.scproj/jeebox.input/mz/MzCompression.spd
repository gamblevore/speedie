


function string.IsCompressed (|bool|)
	return self[0, "mz\n\02"]


function string.Compress (|int| Strength=mzlab.default, |?&compressionstats| st = nil, |faststring?| fs_in = nil,  |string|) 
	|faststring--| fs = FastString(fs_in)
	.Stream.CompressInto(fs, strength, st)
	return fs.GetResult(fs_in)
	

function string.Decompress (|object| Dest=nil, |int|lim=256MB,  |?&compressionstats| st=nil,   |StringThatWasReadSafely|)
	if !.IsCompressed
		return self // for string.parse
	return .stream.decompress(dest, lim, st)


function StringReader.CompressInto (|object| dest, |int| Strength=mzlab.default, |?&compressionstats| st=nil) 
	|| fs = faststring.UseAsOutput(dest)				#require
	st = st.start
	fs <~ "mz\n\02"
	fs.AppendInt(.length)
	st.Out += 8
	while .HasAny
		|| str = .str(4MB)
		|| O = fs.CompressChunk(str, strength)
		|| N = str.length
		st.LiveUpdate(N, O, true)
		fs.flush
	st.end

		
function StringReader.Decompress (|object| dest=nil,  |uint| Limit=256MB,  |&compressionstats| st=nil,  |stringthatwasreadsafely|)
	|| header = .str(4)
	expect (header.IsCompressed)					(self, "Can't decompress non-mz data")
	|| Remain = .UInt(4)
	expect (Remain <= Limit)						(self, "mz would decompress too large")
	
	|| fs = FastString.UseAsOutput(dest)			#require
	|| d = string.error
	if .DecompressSub(fs, st.start, Remain)
		d = fs.GetResult(dest)
	return d



        ////////////////////////////////////////////////////////////////////////////////////////////////

helper StringReader.DecompressSub (|faststring| fs,  |&compressionstats| st,  |int| OutRemain,  |bool|)
	while OutRemain > 0
		|| InSize = .UInt(4) - 4
		expect (InSize < 16MB) 							(self, "mz chunk too large")
		
		|| ChunkData = .str(InSize)
		expect (ChunkData == InSize) 					(self, "mz input too short")
		
		|| OutSize = fs.DecompressChunk(ChunkData)		#loop
		OutRemain -= OutSize
		expect (OutRemain >= 0)							(self, "mz header invalid")		
		// "|uint| Remain" in caller func, did not add up to the sizes found here!
		
		fs.Flush
		st.LiveUpdate(InSize + 4, OutSize, false)

	st.end
	return true



helper faststring.CompressChunk (|string| Input, |int| level, |int|) 
	cpp_wrapper JB_Str_CompressChunk


helper faststring.DecompressChunk (|string| Input, |int|) 
	cpp_wrapper JB_Str_DecompressChunk



/*
		notes:

I could make an "SimplyEscape" header, to avoid the 16-bytes added
in case we are compressing a lot of small strings. Seems fair.

We could simply express the chunk-length as a power of 2, starting from 64K.
Squeeze it in somewhere. Say... in the overall length? Or just have one chunk?
(what about the offsets to the start? they will get large!)
Can we assume that whoever wants this data, wants the whole-data?
perhaps not, if we are compressing a large string, for a large data-bank like a wikipedia dump.

We might want to save it to disk, and later just... load sections at a time.

Perhaps the "final bit-dump" could be 0-stripped, and skipped if it is 0"

The length could be shrunk too. And the header even.

*/





