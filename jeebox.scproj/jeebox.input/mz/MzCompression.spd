


function string.IsCompressed (|bool|)
	return self[0, "mz\n\02"]


function string.Compress (|int| Strength=mzlab.default, |?&compressionstats| st = nil, |faststring?| fs_in = nil,  |string|) 
	|faststring--| fs = FastString(fs_in)
	.Stream.CompressInto(fs, strength, st)
	return fs.GetResult(fs_in)
	

function string.Decompress (|object| Dest=nil, |int|lim=256MB,  |?&compressionstats| st=nil,   |StringThatWasReadSafely|)
	if !.IsCompressed
		return self // for string.parse
	return .stream.decompress(dest, lim, st)


function InputStream.CompressInto (|object| dest, |int| Strength=mzlab.default, |?&compressionstats| st=nil) 
	|| fs = faststring.UseAsOutput(dest)				#require
	st = st.start(compressionstats.compression)
	fs <~ "mz\n\02"
	fs.AppendInt(.length)
	st.Out += 8
	while .HasAny
		|| str = .str(4MB)
		|| O = fs.CompressChunk(str, strength)
		|| N = str.length
		st.LiveUpdate(N, O)
		fs.flush
	st.end

		
function InputStream.Decompress (|object| dest=nil,  |uint| Limit=256MB,  |&compressionstats| st=nil,  |stringthatwasreadsafely|)
	|| header = .str(4)
	expect (header.IsCompressed)					(self, "Can't decompress non-mz data")
	|| Remain = .UInt(4)
	expect (Remain <= Limit)						(self, "mz would decompress too large")
	
	|| fs = FastString.UseAsOutput(dest)			#require
	|| d = string.error
	if .DecompressSub(fs, st.start(compressionstats.decompression), Remain)
		d = fs.GetResult(dest)
	return d



        ////////////////////////////////////////////////////////////////////////////////////////////////

libinternal InputStream.DecompressSub (|faststring| fs,  |&compressionstats| st,  |int| OutRemain,  |bool|)
	while OutRemain > 0
		|| InSize = .UInt(4) - 4
		expect (InSize < 16MB) 							(self, "mz chunk too large")
		
		|| ChunkData = .str(InSize)
		expect (ChunkData == InSize) 					(self, "mz input too short")
		
		|| OutSize = fs.DecompressChunk(ChunkData)		#loop
		OutRemain -= OutSize
		expect (OutRemain >= 0)							(self, "mz header invalid")		
		// "|uint| Remain" in caller func, did not add up to the sizes found here!
		
		fs.Flush
		st.LiveUpdate(InSize + 4, OutSize)

	st.end
	return true



libinternal faststring.CompressChunk (|string| Input, |int| level, |int|) 
	cpp_wrapper JB_Str_CompressChunk


libinternal faststring.DecompressChunk (|string| Input, |int|) 
	cpp_wrapper JB_Str_DecompressChunk



/*
		notes:

I could make an "SimplyEscape" header, to avoid the 16-bytes added
in case we are compressing a lot of small strings. Seems fair.

We could simply express the chunk-length as a power of 2, starting from 64K.
Squeeze it in somewhere. Say... in the overall length? Or just have one chunk?
(what about the offsets to the start? they will get large!)
Can we assume that whoever wants this data, wants the whole-data?
perhaps not, if we are compressing a large string, for a large data-bank like a wikipedia dump.

We might want to save it to disk, and later just... load sections at a time.

Perhaps the "final bit-dump" could be 0-stripped, and skipped if it is 0"

The length could be shrunk too. And the header even.

*/





